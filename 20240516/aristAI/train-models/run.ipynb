{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Application\\WorkApp\\Python\\Anaconda2022\\Anaconda\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "d:\\Application\\WorkApp\\Python\\Anaconda2022\\Anaconda\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\uiuck\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "# Connect to the MySQL database\n",
    "db_connection = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"12345\",\n",
    "    database=\"youtube_data\"\n",
    ")\n",
    "\n",
    "query = \"SELECT id, sentence FROM transcriptions\"\n",
    "df = pd.read_sql(query, db_connection)\n",
    "\n",
    "# Preprocess: Tokenization\n",
    "nltk.download('punkt')\n",
    "df['tokens'] = df['sentence'].apply(nltk.word_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def fine_tune_model(api_key, training_data):\n",
    "    url = \"https://api.gemini.com/v1/fine-tune\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = {\n",
    "        \"training_data\": training_data,\n",
    "        \"model\": \"gemini-model\",\n",
    "        \"num_epochs\": 3\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    return response.json()\n",
    "\n",
    "# Prepare training data\n",
    "training_data = [{'id': row['id'], 'sentence': row['sentence']} for _, row in df.iterrows()]\n",
    "\n",
    "# Fine-tune the model\n",
    "api_key = \"AIzaSyDqPLZhK0dFL3UUDhCiO7mb_NmMWg5x6_M\"\n",
    "fine_tune_response = fine_tune_model(api_key, training_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'generated_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 33>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m GeminiTextGenerationPipeline(api_key\u001b[38;5;241m=\u001b[39mapi_key, database_df\u001b[38;5;241m=\u001b[39mdf)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Generate a response\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m response, referred_ids \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYour question here\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse:\u001b[39m\u001b[38;5;124m\"\u001b[39m, response)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReferred Sentence IDs:\u001b[39m\u001b[38;5;124m\"\u001b[39m, referred_ids)\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mGeminiTextGenerationPipeline.generate\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m     12\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfine-tuned-gemini-model\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt\n\u001b[0;32m     15\u001b[0m }\n\u001b[0;32m     16\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(url, headers\u001b[38;5;241m=\u001b[39mheaders, json\u001b[38;5;241m=\u001b[39mdata)\n\u001b[1;32m---> 17\u001b[0m generated_texts \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgenerated_text\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     18\u001b[0m referred_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatch_generated_texts_to_db(generated_texts)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m generated_texts, referred_ids\n",
      "\u001b[1;31mKeyError\u001b[0m: 'generated_text'"
     ]
    }
   ],
   "source": [
    "class GeminiTextGenerationPipeline:\n",
    "    def __init__(self, api_key, database_df):\n",
    "        self.api_key = api_key\n",
    "        self.database_df = database_df\n",
    "\n",
    "    def generate(self, prompt):\n",
    "        url = \"https://api.gemini.com/v1/generate\"\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        data = {\n",
    "            \"model\": \"fine-tuned-gemini-model\",\n",
    "            \"prompt\": prompt\n",
    "        }\n",
    "        response = requests.post(url, headers=headers, json=data)\n",
    "        generated_texts = response.json()[\"generated_text\"]\n",
    "        referred_ids = self.match_generated_texts_to_db(generated_texts)\n",
    "        return generated_texts, referred_ids\n",
    "\n",
    "    def match_generated_texts_to_db(self, generated_texts):\n",
    "        referred_ids = []\n",
    "        for text in generated_texts:\n",
    "            for idx, sentence in enumerate(self.database_df['sentence']):\n",
    "                if sentence in text:\n",
    "                    referred_ids.append(self.database_df['id'][idx])\n",
    "        return referred_ids\n",
    "\n",
    "# Initialize the pipeline\n",
    "pipeline = GeminiTextGenerationPipeline(api_key=api_key, database_df=df)\n",
    "\n",
    "# Generate a response\n",
    "response, referred_ids = pipeline.generate(\"Your question here\")\n",
    "print(\"Response:\", response)\n",
    "print(\"Referred Sentence IDs:\", referred_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
